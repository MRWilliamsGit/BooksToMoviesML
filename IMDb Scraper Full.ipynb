{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e057b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maria Williams  - Nov, 2021\n",
    "#This script scrapes IMDb for film information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935a1b3",
   "metadata": {},
   "source": [
    "# First Step: \n",
    "Scrape list of movies tagged as 'based on novel' and released from years 1970 to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b14fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aba836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Pass:\n",
    "#1) feature films, 2) tagged 'based on novel', 3) release from years 2000 to 2021: 3,516 titles - 71 pages\n",
    "#baseurl = 'https://www.imdb.com/search/keyword/?keywords=based-on-novel&ref_=kw_nxt&mode=detail&page={}&title_type=movie&release_date=2000%2C2021&sort=year,desc'\n",
    "\n",
    "#Second Pass:\n",
    "#1) feature films, 2) tagged 'based on novel', 3) release from years 2000 to 2021: 6,262 titles - 126 pages\n",
    "baseurl = 'https://www.imdb.com/search/keyword/?keywords=based-on-novel&ref_=kw_ref_yr&mode=detail&page={}&title_type=movie&release_date=1970%2C2000&sort=year,desc'\n",
    "\n",
    "#initialize dataframe\n",
    "popcorn = pd.DataFrame(columns = ['Link','Title', 'Release_Date', 'ViewRating', 'Runtime', 'Genres', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#little function to extract text from bs4 or return blank string\n",
    "def makestring(bs4):\n",
    "    if bs4 is None:\n",
    "        return ' '\n",
    "    else:\n",
    "        return bs4.string\n",
    "    \n",
    "#function to scrape list page\n",
    "def GetPage(baseurl,num):\n",
    "    \n",
    "    pop = pd.DataFrame(columns = ['Link','Title', 'Release_Date', 'ViewRating', 'Runtime', 'Genres', 'Description'])\n",
    "    \n",
    "    page = requests.get(baseurl.format(num))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    main = soup.find_all(attrs={'class':'lister-item mode-detail'})\n",
    "    #print(len(main))\n",
    "\n",
    "    for p in range(len(main)):\n",
    "        #get title\n",
    "        link = main[p].a['href']\n",
    "        title = main[p].h3.a.string\n",
    "        #get description\n",
    "        desc = main[p].find_all('p')\n",
    "        desc = desc[1].string\n",
    "        #get a bunch of other things that may or may not be there  \n",
    "        year = makestring(main[p].find(attrs={'class':'lister-item-year text-muted unbold'}))\n",
    "        rating = makestring(main[p].find(attrs={'class':'certificate'}))\n",
    "        length = makestring(main[p].find(attrs={'class':'runtime'}))\n",
    "        genre = makestring(main[p].find(attrs={'class':'genre'}))\n",
    "        gotit = [link,title,year,rating,length,genre,desc]\n",
    "        pop.loc[len(pop)] = gotit\n",
    "\n",
    "    #print(pop.info())\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4493c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each page has 50 entries\n",
    "#First pass: loop to get a 71 pages\n",
    "#Second pass: loop to get 126 pages\n",
    "\n",
    "for page in range(126):\n",
    "    popper = GetPage(baseurl,page+1)\n",
    "    popcorn = popcorn.append(popper)\n",
    "\n",
    "popcorn['Genres'] = popcorn['Genres'].str.strip()\n",
    "popcorn['Description'] = popcorn['Description'].str.strip()\n",
    "\n",
    "print(popcorn.info())\n",
    "print(popcorn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export dataframe\n",
    "#popcorn.to_csv('FilmList2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05db22",
   "metadata": {},
   "source": [
    "# Second Step: \n",
    "Take list and scrape full IMDB page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37334961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick function to get text from between brackets\n",
    "#turns out I could have just used .string ><\n",
    "def findtext(w):\n",
    "    w = str(w)\n",
    "    w = w[w.find('>')+1:w.find('<', w.find('>'), len(w))]\n",
    "    return w\n",
    "\n",
    "#quick function to get money - does not convert to string at this time\n",
    "def findmoney(w):\n",
    "    w = str(w)\n",
    "    w = w[w.find('$')+1:w.find('<', w.find('$'), len(w))]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "###THIS IS THE FULL SCRAPE OF A PAGE###\n",
    "\n",
    "def Get_Movie(url):\n",
    "    # Request the page and use BeautifulSoup to extract the contents\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #get title\n",
    "    title = soup.find(attrs={'data-testid':'hero-title-block__title'})\n",
    "    title = findtext(title)\n",
    "\n",
    "    #get release date and rating (PG, PG13, etc)\n",
    "    DR = soup.find_all(attrs={'class':'TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex'})\n",
    "    if DR is not None:\n",
    "        if len(DR)==2:\n",
    "            date = findtext(DR[0])\n",
    "            rating = findtext(DR[1])\n",
    "        else:\n",
    "            date = findtext(DR)\n",
    "            rating = None\n",
    "    else:\n",
    "        date = None\n",
    "        rating = None\n",
    "\n",
    "    #get a list of genres\n",
    "    gen = soup.find(attrs={'data-testid':'storyline-genres'}) \n",
    "    if gen is not None:\n",
    "        gen = gen.find_all('a')\n",
    "        genres =''\n",
    "        for t in range(len(gen)):\n",
    "            genres = genres + findtext(gen[t]) + ' '\n",
    "    else:\n",
    "        genres = None\n",
    "\n",
    "    #get box office info\n",
    "    #budget often has '(estimated)' in it\n",
    "    box = soup.find(attrs={'data-testid':'title-boxoffice-section'})\n",
    "    if box is not None:\n",
    "        budget = box.find(attrs={'data-testid':'title-boxoffice-budget'}) \n",
    "        budget = str(budget)\n",
    "        budget = findmoney(budget)\n",
    "        dom = box.find(attrs={'data-testid':'title-boxoffice-grossdomestic'})\n",
    "        dom = findmoney(dom)\n",
    "        ww = soup.find(attrs={'data-testid':'title-boxoffice-cumulativeworldwidegross'}) \n",
    "        ww = findmoney(ww)\n",
    "    else:\n",
    "        budget = None\n",
    "        dom = None\n",
    "        ww = None\n",
    "\n",
    "    \n",
    "    story = soup.find(attrs={'data-testid':'Storyline'}) \n",
    "    if story is not None:\n",
    "        #get the description\n",
    "        desc = story.find(attrs={'class':'ipc-html-content ipc-html-content--base'})\n",
    "        if desc is not None:\n",
    "            desc = desc.div\n",
    "            desc = findtext(desc)\n",
    "        else:\n",
    "            desc = ''\n",
    "        #get top tags\n",
    "        #only shows top few tags, usually list tag is to full list which can be in hundreds\n",
    "        kw = story.find(attrs={'data-testid':'storyline-plot-keywords'}) \n",
    "        if kw is not None:\n",
    "            kw = kw.find_all('span')\n",
    "            keywords = ''\n",
    "            for t in range(len(kw)):\n",
    "                #keywords.append(findtext(kw[t]))\n",
    "                keywords = keywords + findtext(kw[t]) + ' '\n",
    "        else:\n",
    "            keywords = None\n",
    "    else:\n",
    "        desc = None\n",
    "        keywords = None\n",
    "\n",
    "    #get runtime in minutes\n",
    "    rt = soup.find(attrs={'data-testid':'title-techspec_runtime'}) \n",
    "    if rt is not None:\n",
    "        rt = rt.find('div')\n",
    "        hrs = findtext(rt)\n",
    "        rt = str(rt)\n",
    "        mins = rt[::-1]\n",
    "        mins = mins[7:]\n",
    "        mins = mins[mins.find('<')+1:mins.find('>', mins.find('<'), len(mins))]\n",
    "        if hrs==' ':\n",
    "            runtime = int(mins)\n",
    "        elif mins==' ':\n",
    "            runtime = int(hrs)*60\n",
    "        else:\n",
    "            runtime = int(hrs)*60 + int(mins)\n",
    "    else:\n",
    "        runtime = None\n",
    "\n",
    "    #put all that info in a list and return it \n",
    "    obs = [title,date,rating, genres, budget,dom,ww,desc,keywords, runtime]\n",
    "    \n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok now pull in our list of movies\n",
    "#movies = pd.read_csv(r'C:\\Users\\maria\\OneDrive\\Documents\\AIPI510\\BooksToMoviesML\\FilmList.csv') <--- original 2000-2021 list\n",
    "movies = pd.read_csv(r'C:\\Users\\maria\\OneDrive\\Documents\\AIPI510\\BooksToMoviesML\\FilmList2.csv')\n",
    "movies = movies['Link']\n",
    "\n",
    "#instantiate dataframe\n",
    "data = pd.DataFrame(columns = ['Title', 'Release_Date', 'ViewRating', 'Genres', 'Budget', 'DomesticGross', \n",
    "                              'WorldwideGross', 'Description', 'Keywords', 'Runtime'])\n",
    "\n",
    "#scrape provided pages\n",
    "#this counter is because i had to run it in batches\n",
    "movies = movies[4610:]\n",
    "\n",
    "for this in movies:\n",
    "    #print(this)\n",
    "    obs = Get_Movie('https://www.imdb.com{}'.format(this))\n",
    "    data.loc[len(data)] = obs\n",
    "    \n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('New1652.csv',index=False)\n",
    "#2106 first pull, 2505 next pull, 1652 last pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6283ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is just to slap everything together since I had trouble running the full scrape\n",
    "\n",
    "one = pd.read_csv('New2106.csv')\n",
    "two = pd.read_csv('New2505.csv')\n",
    "three = pd.read_csv('New1652.csv')\n",
    "\n",
    "together = pd.concat([one,two,three])\n",
    "#together = together.applymap(str)\n",
    "together.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "print(together.info())\n",
    "\n",
    "#together.to_csv('IMDbScrape2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
