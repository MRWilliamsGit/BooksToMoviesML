{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraper to take links collected by LibraryThingScraper\n",
    "#return scrape of website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0af24501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8c7ba558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBookPlease(page):\n",
    "    \n",
    "    print(page)\n",
    "        \n",
    "    #get response\n",
    "    response = requests.get(url='https://www.librarything.com'+ page).text\n",
    "    soup = BeautifulSoup(response, features=\"html.parser\")\n",
    "    \n",
    "    #get top of page - author, publish date, if part of series\n",
    "    top = soup.find(attrs={'class':'headsummary'})\n",
    "    published = top.find(attrs={'class':'date'}).string #hope this always exists\n",
    "    author = top.find('h2').text                        #hope this always exists\n",
    "    stuff = top.find_all('h3')                          #this will always exist\n",
    "    for e in stuff:\n",
    "        if 'Series:' in e.text:\n",
    "            series = 1\n",
    "        else:\n",
    "            series = 0\n",
    "    \n",
    "    #get rating\n",
    "    rating = soup.find(attrs={'class':'dark_hint'})\n",
    "    if rating != None:\n",
    "        rating = soup.find(attrs={'class':'dark_hint'}).text\n",
    "        \n",
    "    #get number of characters\n",
    "    groups = soup.find_all(attrs={'class':'fwikiGroup'})\n",
    "    for g in range(len(groups)):\n",
    "        hm = groups[g].find(attrs={'fieldname':'characternames'})\n",
    "        if hm is not None:\n",
    "            place = g\n",
    "    charnum = groups[place].find(attrs={'class':'itemnumberoverflow'})\n",
    "    if charnum is None:\n",
    "        charnum = groups[place].find_all(attrs={'class':'fwikiAtomicValue'})\n",
    "        charnum = len(charnum)\n",
    "    else:\n",
    "        charnum = groups[place].find(attrs={'class':'itemnumberoverflow'}).text\n",
    "        charnum = re.findall(r'\\d+', charnum)[0]\n",
    "\n",
    "    #get number of awards\n",
    "    #would be nice to have titles but not enough time\n",
    "    for g in range(len(groups)):\n",
    "        hm = groups[g].find(attrs={'fieldname':'awards'})\n",
    "        if hm is not None:\n",
    "            place = g\n",
    "    awardnum = groups[place].find(attrs={'class':'itemnumberoverflow'})\n",
    "    if awardnum is None:\n",
    "        awardnum = groups[place].find_all(attrs={'class':'fwikiAtomicValue'})\n",
    "        awardnum = len(awardnum)\n",
    "    else:\n",
    "        awardnum = groups[place].find(attrs={'class':'itemnumberoverflow'}).text\n",
    "        awardnum = re.findall(r'\\d+', awardnum)[0]\n",
    "        \n",
    "    #print(charnum)\n",
    "    return [page, published, author, series, rating, charnum, awardnum]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c6086875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in the link list\n",
    "moviesdb = pd.read_csv('LTlinksFull.csv')\n",
    "\n",
    "#make a list of book links\n",
    "links = moviesdb['Link2']\n",
    "\n",
    "#print(links.isna().sum())\n",
    "for m in range(len(links)):\n",
    "    if str(links[m])=='nan':\n",
    "        if r']' not in moviesdb.loc[m, 'SearchTerm']:\n",
    "            #print(moviesdb.loc[m, 'Link2'])\n",
    "            links[m] = moviesdb.loc[m, 'Link1']\n",
    "\n",
    "#print(links[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ec439a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/21214\n",
      "/work/364\n",
      "/work/24434168\n",
      "/work/21623\n",
      "/work/831523\n",
      "/work/23961085\n",
      "/work/6664405\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-a2ba0b024ecb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'nan'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mgrab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetBookPlease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mlibrary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-210-cfeb36ae0706>\u001b[0m in \u001b[0;36mGetBookPlease\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#get top of page - author, publish date, if part of series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'headsummary'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mpublished\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[1;31m#hope this always exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mauthor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m                        \u001b[1;31m#hope this always exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mstuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h3'\u001b[0m\u001b[1;33m)\u001b[0m                          \u001b[1;31m#this will always exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'string'"
     ]
    }
   ],
   "source": [
    "library = pd.DataFrame(columns = ['link','published', 'author', 'series', 'rating', 'charnum', 'awardnum'])\n",
    "#links = ['/work/4041453', '/work/1906740', '/work/4725', '/work/5716']\n",
    "\n",
    "for l in range(len(links)):\n",
    "    if str(links[l]) != 'nan':\n",
    "        grab = GetBookPlease(links[l])\n",
    "        library = library.append(pd.Series(grab, index = library.columns), ignore_index=True)\n",
    "\n",
    "print(library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a380fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting pull at 3:17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
