{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abd33ba",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b236f53a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-52f6c2e654ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cebc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb921ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb1 = pd.read_csv('IMDbScrapeFull.csv')\n",
    "imdb2 = pd.read_csv('IMDbScrape2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108aa0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbfull = pd.concat([imdb1,imdb2], axis=0)\n",
    "movie = imdbfull.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa727d",
   "metadata": {},
   "source": [
    "# Begin Cleaning\n",
    "    - Drop domestic gross profit and use worldwide gross profit\n",
    "    - Clean worldwide gross profit\n",
    "    - Clean budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14370d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DomesticGross' in movie.columns:\n",
    "    \n",
    "    flag = True # used in next block to ensure rerunning block doesn't throw error\n",
    "    \n",
    "    movie = movie.iloc[89:,:] # drop movies made in 2021 since incomplete data\n",
    "    movie = movie.drop(labels = ['DomesticGross'], axis = 1) # drop domestic, worldwide is more important\n",
    "    movie['WorldwideGross'] = movie['WorldwideGross'].str.replace(',','')\n",
    "    movie['Budget'] = movie['Budget'].str.replace(',','')\n",
    "    movie['Budget'] = movie['Budget'].str.split(' ').str[0]\n",
    "    movie = movie.dropna(subset = ['WorldwideGross'], axis = 0)\n",
    "    movie = movie.reset_index(drop = True)\n",
    "\n",
    "    for i in range(movie['WorldwideGross'].shape[0]): \n",
    "        if (movie['WorldwideGross'].loc[i] == 'Non') | (movie['WorldwideGross'].loc[i][0] == '<'):\n",
    "            movie = movie.drop(index = i)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    movie = movie.reset_index(drop = True)\n",
    "\n",
    "            \n",
    "    for i in range(movie['Budget'].shape[0]): \n",
    "        if (movie['Budget'].loc[i] == 'Non') | (movie['Budget'].loc[i][0] == '<'):\n",
    "            movie = movie.drop(index = i)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    movie = movie.reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "\n",
    "movie['WorldwideGross'] = movie['WorldwideGross'].astype(int)\n",
    "movie['Budget'] = movie['Budget'].astype(int)\n",
    "movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b454a17",
   "metadata": {},
   "source": [
    "# Organizing, reshuffling, renaming etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc13024",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag: \n",
    "    flag = False\n",
    "    movie = movie.rename(columns = {'Release_Date': 'Year','ViewRating':'Rating'})\n",
    "    movie['Revenue-Budget-Ratio'] = movie['WorldwideGross'] / movie['Budget']\n",
    "    movie['Year'] = movie['Year'].astype(int)\n",
    "    movie['Runtime'] = movie['Runtime'].astype(int)\n",
    "    \n",
    "    movie['Rating'] = movie['Rating'].fillna('Unknown')\n",
    "\n",
    "# VISUALIZATION: \n",
    "\n",
    "print(movie['Revenue-Budget-Ratio'].describe()) # aggregate statistics\n",
    "print('')\n",
    "print('Median:',movie['Revenue-Budget-Ratio'].median()) \n",
    "\n",
    "\n",
    "target = movie['Revenue-Budget-Ratio']\n",
    "bins = np.arange(0,20,1)\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.hist(target, bins = bins)\n",
    "plt.title('Distribution of Revenue-Budget-Ratio')\n",
    "plt.xlabel('Revenue-Budget-Ratio')\n",
    "plt.ylabel('Number of movies')\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "target.plot(kind = 'kde', color = 'orange' )\n",
    "plt.title('KDE')\n",
    "plt.xlabel('Revenue-Budget-Ratio')\n",
    "plt.xlim(-1,20)\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.boxplot(target)\n",
    "plt.title('Boxplot')\n",
    "plt.ylabel('Revenue-Budget-Ratio')\n",
    "plt.ylim(-1,35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e44d3",
   "metadata": {},
   "source": [
    "# Distribution is clearly exponential or poisson - I THINK??\n",
    "Analysis: \n",
    "\n",
    "This makes sense. A larger ratio is a financially successful movie. Many movies are not successful, and in fact for every ~10 movies only about 3 are successful, paying for the 7 unsuccessful ones. Subsequently, it makes perfect sense that the distribution of this revenue/budget ratio is skewed heavily towards the lower end. \n",
    "\n",
    "A ratio of 1 means that the company actually lost money on the movie, since revenue does not take into account costs, so the profit would be less than the budget (i.e. a loss). \n",
    "\n",
    "The median of the data is 1.29 and the mean is 2.48. Therefore, while we don't have a lot of data, it does seem to be representative of the overall larger distribution of movies. The median revenue/budget ratio is a financial loss, and the mean is a bit better since it includes the outliers (the successful movies). \n",
    "\n",
    "While there are a lot of outliers here (as seen on the boxplot), these are very imporatnt to include since ultimately when a movie studio makes a movie, they want to be the outlier themselves. (outlier = highly profitable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = movie.drop(labels = ['Budget','WorldwideGross'], axis = 1) # dropping these since our target is a function of these two features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9ceb9",
   "metadata": {},
   "source": [
    "# Ordinal Encoding Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(movie.shape[0]):\n",
    "    if (movie['Rating'].loc[i]) == '':\n",
    "        continue\n",
    "    elif (movie['Rating'].loc[i]) == 'TV-PG':\n",
    "        movie['Rating'].loc[i] = 'PG'\n",
    "    elif (movie['Rating'].loc[i]) == 'Unrated':\n",
    "        movie['Rating'].loc[i] = 'Not Rated'\n",
    "    elif (movie['Rating'].loc[i]) == 'TV-14':\n",
    "        movie['Rating'].loc[i] = 'PG-13'\n",
    "    elif (movie['Rating'].loc[i]) == 'TV-MA':\n",
    "        movie['Rating'].loc[i] = 'NC-17'\n",
    "    elif (movie['Rating'].loc[i]) == 'X':\n",
    "        movie['Rating'].loc[i] = 'NC-17'\n",
    "    elif (movie['Rating'].loc[i]) == 'GP':\n",
    "        movie['Rating'].loc[i] = 'PG'\n",
    "    elif (movie['Rating'].loc[i]) == 'Approved':\n",
    "        movie['Rating'].loc[i] = 'R'\n",
    "        \n",
    "# ordinal encoding myself\n",
    "\n",
    "ratings = {'G':0.0, 'PG':1.0, 'PG-13':2.0,'R':3.0,'NC-17':4.0, 'Not Rated':5.0, 'Unknown':6.0} # dictionary mapping\n",
    "movie['Rating'] = movie['Rating'].replace(ratings) # replace categories with ordinally encoded values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f22ba4",
   "metadata": {},
   "source": [
    "# One-Hot Encoding Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646aeb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie['Genres'] = movie['Genres'].str.split(' ').str[0] # grab first genre in list and assign this as the movie's single genre\n",
    "movie = movie.rename(columns = {'Genres':'Genre'}) # rename to singular form\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87fbe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if flag:\n",
    "    flag = False\n",
    "    enc = OneHotEncoder(handle_unknown='ignore') # one-hot encoder\n",
    "    enc.fit(np.array(movie['Genre']).reshape(-1,1))\n",
    "\n",
    "    columns = list(enc.get_feature_names())\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i].split('_')[-1]\n",
    "\n",
    "    enc_vals = enc.transform(np.array(movie['Genre']).reshape(-1,1))\n",
    "    enc_df = pd.DataFrame(enc_vals.toarray(), columns = columns)\n",
    "\n",
    "    targets = movie['Revenue-Budget-Ratio']\n",
    "    movie = pd.concat([movie.drop(labels = ['Revenue-Budget-Ratio','Genre'], axis = 1),enc_df,targets], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c425d19",
   "metadata": {},
   "source": [
    "# Remove additional duplicates that Maria found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b86d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movie = movie[~movie.duplicated()]\n",
    "movie = movie.reset_index(drop = True)\n",
    "\n",
    "for i in range(movie.shape[0]):\n",
    "    movie['Title'].loc[i] = re.sub(r'[^\\w\\s]','', movie['Title'].loc[i]) # strip inconsistent punctuation to make merging easier\n",
    "\n",
    "movie # this is final, pre-merge movie dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3042778",
   "metadata": {},
   "source": [
    "# Merge with cleaned book data from Miranda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afde0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = pd.read_csv('mm_LibraryThingFull.csv')\n",
    "book = book.drop(labels = ['Link1','Link2'],axis = 1)\n",
    "book['SearchTerm'] = book['SearchTerm'].str.split(' \\[').str[0]\n",
    "\n",
    "book['Year'] = book['Year'].str.split('[').str[-1].str.split(' film').str[0]\n",
    "book['author_x'] = book['author_x'].str.split('by ').str[-1]\n",
    "book = book.rename(columns = {'SearchTerm':'movie_title','Year':'movie_year' ,'AdaptationOf':'book_title','published_x':'book_year','author_x':'author','series_x':'num_books_in_series','rating_x':'book_rating','charnum_x':'charnum','awardnum_x':'awardnum'})\n",
    "\n",
    "books_and_movies = pd.merge(movie,book, how = 'inner', left_on = 'Title', right_on = 'movie_title')\n",
    "books_and_movies = books_and_movies.drop_duplicates(subset = ['Title','Year']) # drop any duplicate entries in the dataframe\n",
    "books_and_movies = books_and_movies.reset_index(drop = True)\n",
    "\n",
    "test = pd.merge(movie,book, how = 'inner', left_on = 'Title', right_on = 'book_title')\n",
    "test = test.drop_duplicates(subset = ['Title','Year']) # drop any duplicate entries in the dataframe\n",
    "test = test.reset_index(drop = True)\n",
    "\n",
    "books_and_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffd9a5",
   "metadata": {},
   "source": [
    "# Analysis of books_and_movies\n",
    "- Data distribution still representative of overall distribution of movies, as you can tell by the shape of the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec866b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "books_and_movies = books_and_movies.drop(labels = ['movie_title','book_title','movie_year'], axis = 1)\n",
    "\n",
    "\n",
    "target = books_and_movies['Revenue-Budget-Ratio']\n",
    "print(target.describe())\n",
    "print('')\n",
    "print('Median:',target.median())\n",
    "\n",
    "bins = np.arange(0,25,1)\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.hist(target, bins = bins)\n",
    "\n",
    "\n",
    "books_and_movies['book_rating'] = books_and_movies['book_rating'].fillna(books_and_movies['book_rating'].median())\n",
    "books_and_movies['book_rating'] = (books_and_movies['book_rating'].astype(float) * -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfff75f",
   "metadata": {},
   "source": [
    "# Import NYT Bestsellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eded20",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes = pd.read_csv('NYCBestsellers.csv')\n",
    "best_authors = nytimes['author'].drop_duplicates().reset_index(drop = True)\n",
    "our_authors = books_and_movies['author'].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "# best_authors\n",
    "# our_authors\n",
    "test = pd.merge(best_authors,our_authors, how = 'inner')\n",
    "\n",
    "books_and_movies['NYTBestsellingAuthor'] = 0\n",
    "\n",
    "for i in range(books_and_movies.shape[0]):\n",
    "    if (books_and_movies['author'].loc[i] in list(test['author'])):\n",
    "        books_and_movies['NYTBestsellingAuthor'].loc[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252733c3",
   "metadata": {},
   "source": [
    "# Select things made in or after 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_and_movies = books_and_movies[books_and_movies['Year']>=2008]\n",
    "books_and_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365c665",
   "metadata": {},
   "source": [
    "# Feature correlation analysis with target: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = books_and_movies['Revenue-Budget-Ratio']\n",
    "books_and_movies = pd.concat([targ,books_and_movies.drop(labels = ['Revenue-Budget-Ratio'], axis = 1)],axis = 1)\n",
    "correlation = books_and_movies.corr()\n",
    "correlation.iloc[1:,:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b26cc9",
   "metadata": {},
   "source": [
    "# Prepare for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = books_and_movies['Revenue-Budget-Ratio']\n",
    "books_and_movies = books_and_movies.drop(labels = ['Title','Description','Keywords','author','Revenue-Budget-Ratio'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2703a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_and_movies['num_books_in_series'] = books_and_movies['num_books_in_series'].fillna(1)\n",
    "books_and_movies['charnum'] = books_and_movies['charnum'].fillna(books_and_movies['charnum'].median())\n",
    "books_and_movies['awardnum'] = books_and_movies['awardnum'].fillna(0)\n",
    "books_and_movies['book_year'] = books_and_movies['book_year'].fillna(books_and_movies['book_year'].median()) # this is a questionable decision?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58eabeb",
   "metadata": {},
   "source": [
    "# Convert continuous output to categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303e96b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = books_and_movies\n",
    "y = targets\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if (y.iloc[i] < 5):\n",
    "        y.iloc[i] = 0\n",
    "    else:\n",
    "        y.iloc[i] = 1\n",
    "        \n",
    "print(y.value_counts())\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X,y,stratify=y, test_size = 0.20)\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.bar([0,1],height = [y.value_counts()[0.0],y.value_counts()[1.0]])\n",
    "plt.xticks([0,1])\n",
    "plt.title('Class Imbalance Visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d53e3",
   "metadata": {},
   "source": [
    "# Model creation / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad55c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_auroc(X,y,estimator,num_iter):\n",
    "    \n",
    "    auroc = []\n",
    "    \n",
    "    for n in range(num_iter):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X,y,stratify = y,test_size = 0.20)\n",
    "        \n",
    "        sm = SMOTE(random_state = 42) # SMOTE\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        \n",
    "        estimator.fit(X_train,y_train)\n",
    "        preds = estimator.predict(X_val)\n",
    "        auroc.append(roc_auc_score(y_val,preds))\n",
    "    \n",
    "    return np.round(np.mean(auroc),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87c1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lg = get_average_auroc(X_train_full,y_train_full,LogisticRegression(),100)\n",
    "print('Average logistic regression AUROC:',lg)\n",
    "\n",
    "mlp = get_average_auroc(X_train_full,y_train_full,MLPClassifier(),25)\n",
    "print('Average mlp AUROC:',mlp)\n",
    "\n",
    "rf = get_average_auroc(X_train_full,y_train_full,RandomForestClassifier(max_depth=4, n_estimators=100),25)\n",
    "print('Average rf AUROC:',rf)\n",
    "\n",
    "knn = get_average_auroc(X_train_full,y_train_full,KNeighborsClassifier(),100)\n",
    "print('Average knn AUROC:',knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a9655b",
   "metadata": {},
   "source": [
    "# We are choosing logistic regression as it is best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70219b55",
   "metadata": {},
   "source": [
    "# Evaluate final model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d3bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = []\n",
    "\n",
    "final_model = LogisticRegression()\n",
    "final_model.fit(X_train_full,y_train_full)\n",
    "preds = final_model.predict(X_test)\n",
    "auroc.append(roc_auc_score(y_test,preds))\n",
    "    \n",
    "print('AUROC on single trial:',np.round(np.mean(auroc),3))\n",
    "\n",
    "print(classification_report(y_test,preds))\n",
    "\n",
    "auroc = []\n",
    "precision = []\n",
    "\n",
    "for _ in range(150):\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(X,y,stratify=y, test_size = 0.20)\n",
    "    final_model = LogisticRegression()\n",
    "    final_model.fit(X_train_full,y_train_full)\n",
    "    preds = final_model.predict(X_test)\n",
    "    auroc.append(roc_auc_score(y_test,preds))\n",
    "    precision.append(classification_report(y_test,preds, output_dict = True)['1.0']['precision'])\n",
    "\n",
    "print('Average AUROC over 100 trials:',np.round(np.mean(auroc),3))\n",
    "print('Average precision for 1.0 class over 100 trials:',np.round(np.mean(precision),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3300b",
   "metadata": {},
   "source": [
    "# Logistic Regression averaging 0.577 AUROC over 100 trials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
