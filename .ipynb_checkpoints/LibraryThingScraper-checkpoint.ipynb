{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library thing scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a0cfda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5b33b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function receives a movie title and year and returns the title and link \n",
    "def ScrapeSearch(title, moviedate):\n",
    "    \n",
    "    #url puzzle pieces\n",
    "    baseurl = 'https://www.librarything.com/search.php?search={}&searchtype=newwork_titles&searchtype=newwork_titles&sortchoice=0'\n",
    "    bbaseurl = 'https://www.librarything.com'\n",
    "    search = title + ' ['+ str(moviedate)+ ' film]'\n",
    "    \n",
    "    #initiate driver\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome('chromedriver', options=options)\n",
    "    driver2 = webdriver.Chrome('chromedriver', options=options)\n",
    "    \n",
    "    #wait for page to load item, then get contents\n",
    "    try:\n",
    "        driver.get(baseurl.format(search))\n",
    "        timeout = 10\n",
    "        WebDriverWait(driver, timeout).until(ec.presence_of_element_located((By.CLASS_NAME, 'item')))\n",
    "        stuff = driver.page_source\n",
    "        driver.quit()\n",
    "\n",
    "        #get the first item title and link\n",
    "        soup = BeautifulSoup(stuff, features=\"html.parser\")\n",
    "        please = soup.find_all(attrs={'id':'ajaxcontent'})\n",
    "        please = soup.find_all(attrs={'class':'item'})\n",
    "        please = please[0].find('a')\n",
    "        title = please.string\n",
    "        link1 = please['href']\n",
    "        \n",
    "        #go to the link and pull the book title and link\n",
    "        try:\n",
    "            driver2.get('https://www.librarything.com'+link1)\n",
    "            timeout = 5\n",
    "            WebDriverWait(driver2, timeout).until(ec.presence_of_element_located((By.ID, 'relationships_container')))\n",
    "            stuff = driver2.page_source\n",
    "            driver2.quit()\n",
    "            \n",
    "            #get the book title and link\n",
    "            soup = BeautifulSoup(stuff, features=\"html.parser\")\n",
    "            yes = soup.find(attrs={'id':'relationships_container'})\n",
    "            hm = soup.find(text=\"Is an adaptation of\")\n",
    "            if type(hm) == type(None):\n",
    "                book = 'not found'\n",
    "                link2 = 'not found'\n",
    "            else:\n",
    "                yes = soup.find(text=\"Is an adaptation of\").find_next()\n",
    "                yes = yes.find(attrs={'class':'popup_registered'})\n",
    "                book = yes.string\n",
    "                link2 = yes['href']\n",
    "            \n",
    "        except TimeoutException:\n",
    "            book = 'not found'\n",
    "            link2 = 'not found'\n",
    "        \n",
    "    except TimeoutException:\n",
    "        link1 = 'not found'\n",
    "        book = 'not found'\n",
    "        link2 = 'not found'\n",
    "        \n",
    "    #return them\n",
    "    return [title, link1, book, link2]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d1ecaa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the function that searches for the movie title and date\n",
    "#it returns the title it finds (in case it is different than the search term) and a link to the first result\n",
    "def MovieFirst(baseurl, title):\n",
    "    \n",
    "    print(baseurl.format(title))\n",
    "    \n",
    "    #initiate driver\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome('chromedriver', options=options)\n",
    "\n",
    "    #wait for page to load item, then get contents\n",
    "    try:\n",
    "        driver.get(baseurl.format(search))\n",
    "        timeout = 10\n",
    "        WebDriverWait(driver, timeout).until(ec.presence_of_element_located((By.CLASS_NAME, 'item')))\n",
    "        stuff = driver.page_source\n",
    "        driver.quit()\n",
    "\n",
    "        #get the first item title and link\n",
    "        soup = BeautifulSoup(stuff, features=\"html.parser\")\n",
    "        please = soup.find_all(attrs={'id':'ajaxcontent'})\n",
    "        please = soup.find_all(attrs={'class':'item'})\n",
    "        please = please[0].find('a')\n",
    "        #title = please.string\n",
    "        #link1 = please['href']\n",
    "        hep = please.string\n",
    "        plz = please['href']\n",
    "        print(hep)\n",
    "        print(plz)\n",
    "                \n",
    "    except TimeoutException:\n",
    "        link1 = 'not found'\n",
    "\n",
    "    return title, link1\n",
    "\n",
    "#this is the function that receives a movie link \n",
    "#it returns the book title and link \n",
    "def BookSecond(link1):\n",
    "    \n",
    "    #initiate driver\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    driver2 = webdriver.Chrome('chromedriver', options=options)\n",
    "    \n",
    "    #go to the link and pull the book title and link\n",
    "    try:\n",
    "        driver2.get('https://www.librarything.com'+link1)\n",
    "        timeout = 5\n",
    "        WebDriverWait(driver2, timeout).until(ec.presence_of_element_located((By.ID, 'relationships_container')))\n",
    "        stuff = driver2.page_source\n",
    "        driver2.quit()\n",
    "\n",
    "        #get the book title and link\n",
    "        soup = BeautifulSoup(stuff, features=\"html.parser\")\n",
    "        yes = soup.find(attrs={'id':'relationships_container'})\n",
    "        hm = soup.find(text=\"Is an adaptation of\")\n",
    "        if type(hm) == type(None):\n",
    "            book = 'not found'\n",
    "            link2 = 'not found'\n",
    "        else:\n",
    "            yes = soup.find(text=\"Is an adaptation of\").find_next()\n",
    "            yes = yes.find(attrs={'class':'popup_registered'})\n",
    "            book = yes.string\n",
    "            link2 = yes['href']\n",
    "\n",
    "    except TimeoutException:\n",
    "        book = 'not found'\n",
    "        link2 = 'not found'\n",
    "\n",
    "    return book, link2\n",
    "\n",
    "#this function receives a movie title and year\n",
    "#it uses the \"MovieFirst\" and 'BookSecond' functions\n",
    "#it returns the found movie title, the link to the movie entry, the book title, and the link to the book entry\n",
    "def ScrapeSearch(title, moviedate):\n",
    "        #print(title)\n",
    "        #url puzzle pieces\n",
    "        baseurl = 'https://www.librarything.com/search.php?search={}&searchtype=newwork_titles&searchtype=newwork_titles&sortchoice=0'\n",
    "        search = title + ' ['+ str(moviedate)+ ' film]'    \n",
    "   \n",
    "        #search by movie and date\n",
    "        print(search)\n",
    "        title, link1 = MovieFirst(baseurl, search)\n",
    "        #print(title, link1)\n",
    "        #if no results, search by movie title only and assume it pulls up the book\n",
    "        if link1 == 'not found':\n",
    "            book, link2 = MovieFirst(baseurl, title)\n",
    "            link1 = 'not found, book details are result of title search'\n",
    "        #if movie results found, go into movie entry and get the book title and link\n",
    "        else:\n",
    "            book, link2 = BookSecond(link1)\n",
    "            \n",
    "        #return them\n",
    "        return [title, link1, book, link2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "3dae27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in the IMDb list (1373 lines)\n",
    "moviesdb = pd.read_csv('CleanMovieData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "fe228d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop through the movie list and make a table\n",
    "ohgood = pd.DataFrame(columns = ['SearchTerm', 'MovieLink', 'BookTitle', 'BookLink'])\n",
    "\n",
    "moviesdb = moviesdb.iloc[9:10]\n",
    "\n",
    "for hm in moviesdb.index:\n",
    "    hello = ScrapeSearch(moviesdb.Title[hm], moviesdb.Date[hm])\n",
    "    #print(hello)\n",
    "    ohgood = ohgood.append(pd.Series(hello, index = ohgood.columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "57dacced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 SearchTerm       MovieLink     BookTitle     BookLink\n",
      "0  Pet Sematary [2019 film]  /work/23112491  Pet Sematary  /work/24308\n"
     ]
    }
   ],
   "source": [
    "print(ohgood)\n",
    "\n",
    "#pulls the tag cloud - not sure where the check comes from \n",
    "#content = requests.get(\"http://www.librarything.com/ajax_work_makeworkCloud.php?work=3203347&check=2801929225\").text\n",
    "#soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18b40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
